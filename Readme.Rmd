---
title: "ST558, Project3"
author: "Jacob Press, Nataliya Peshekhodko"
date: "`r Sys.Date()`"
---



# Introduction

This report build for education level `r params$education_level`.

# Packages

```{r, warning=FALSE, message=FALSE}
library(tidyverse)
library(caret)
library(ggplot2)
library(corrplot)
library(caret)
library(Metrics)
```


# Data

Reading data from `csv` file.

```{r, warning=FALSE, message=FALSE}
data = read_csv('./data/diabetes_binary_health_indicators_BRFSS2015.csv')
```


Checking for NA values
```{r}
sum(is.na(data))
```

There are no missing values in the data set.

Let's look at the head of data.
```{r}
head(data)
```

Combine Education levels `1` and `2` into one level `12`

```{r}
transformed <- data %>%
  mutate (Education = if_else(Education == 1 | Education == 2, 12, Education))
```

Sub-setting data for the selected education level:

```{r}
education_level = params$education_level

subset <- transformed %>%
  filter(Education == education_level)
```

Checking data structure:

```{r}
str(subset)
```


Variables in data set:

  - **Diabetes_binary** - 0 = no diabetes, 1 = diabetes
  - **HighBP** - 0 = no high blood pressure, 1 = high blood pressure
  - **HighChol** - 0 = no high cholesterol, 1 = high cholesterol
  - **CholCheck** - 0 = no cholesterol check in 5 years,  1 = yes cholesterol check in 5 years
  - **BMI** - Body Mass Index
  - **Smoker** - Have you smoked at least 100 cigarettes in your entire life? 0 = no, 1 = yes
  - **Stroke** - (Ever told) you had a stroke. 0 = no,  1 = yes
  - **HeartDiseaseorAttack** - Coronary heart disease (CHD) or myocardial infarction (MI), 0 = no, 1 = yes
  - **PhysActivity** - Physical activity in past 30 days - not including job,  0 = no, 1 = yes
  - **Fruits** - Consume Fruit 1 or more times per day, 0 = no, 1 = yes
  - **Veggies** - Consume Vegetables 1 or more times per day, 0 = no 1 = yes
  - **HvyAlcoholConsump** - Heavy drinkers (adult men having more than 14 drinks per week and adult women having more than 7 drinks per week) 0 = no
  - **AnyHealthcare** - Have any kind of health care coverage, including health insurance, prepaid plans such as HMO, etc. 0 = no 1 = yes
  - **NoDocbcCost** - Was there a time in the past 12 months when you needed to see a doctor but could not because of cost? 0 = no 1 = yes
  - **GenHlth** - Would you say that in general your health is: scale 1-5 1 = excellent 2 = very good 3 = good 4 = fair 5 = poor
  - **MentHlth** - Now thinking about your mental health, which includes stress, depression, and problems with emotions, for how 
  - **PhysHlth** - Now thinking about your physical health, which includes physical illness and injury, for how many days during the past 30 
  - **DiffWalk** - Do you have serious difficulty walking or climbing stairs? 0 = no, 1 = yes
  - **Sex** - 0 = female,  1 = male
  - **Age** - 13-level age category, 1 = 18-24, 9 = 60-64,  13 = 80 or older
  - **Education** - Education level scale 1-6, 1 = Never attended school or only kindergarten,  2 = Grades 1 through 8
  - **Income** - Income scale scale 1-8,  1 = less than 10,000 dol,  5 = less than 35,000 dol,  8 = 75,000 dol or more
  

# Explanatory Data Analysis(EDA)

First, let's look at number of thr records with Diabetes and without Diabetes for the selected education level:

```{r}
table (factor (subset$Diabetes_binary, labels = c("No diabet", "Diabet")) )
```

Let's look at `Age` distribution for the selected education level:

```{r, message=FALSE}
ggplot(data = subset, aes(x = Age)) +
  geom_histogram(color = "black", fill = 'brown') +
  labs(title = "Histogram of Age groups distribution", 
       x = "Age group", 
       y = "Frequency")
```

Let's look at number of cases with Diabetes and without Diabetes for each age group for the selected education level

```{r}
# TODO: update levels for ages
table(factor(subset$Diabetes_binary, labels = c("No diabet", "Diabet")), subset$Age)
```
Number of cases with Diabetes and without Diabetes for males and females.

```{r}
table(factor (subset$Diabetes_binary, labels = c("No diabet", "Diabet")), 
      factor(subset$Sex, labels = c("Female", "Male")))
```

Linear correlation between numeric variables.

```{r}
corrplot(cor(as.matrix(subset %>% select(-Education))), 
         type="upper", 
         tl.pos = "lt")
```

Number of cases with Diabetes and without Diabetes for each general health level.

```{r}
#TODO: update levels
table(factor(subset$Diabetes_binary, labels = c("No diabet", "Diabet")), 
      subset$GenHlth)
```
Number of cases with Diabetes and without Diabetes for high blood pressure and normal blood pressure patients.

```{r}
table(factor(subset$Diabetes_binary, labels = c("No diabet", "Diabet")), 
      factor(subset$HighBP, labels = c("No high BP", "High BP")) )
```

Number of cases with Diabetes and without Diabetes for high cholesterol and normal cholesterol patients.

```{r}
table(factor(subset$Diabetes_binary, labels = c("No diabet", "Diabet")), 
      factor (subset$HighChol, labels = c("No high chol", "High chol")))
```

BMI distribution for patients with Diabetes and without Diabetes for the selected education level.

```{r}
ggplot(subset, aes(x = as_factor(Diabetes_binary), 
                   y = BMI, 
                   fill = as_factor(Diabetes_binary))) +
  geom_boxplot() +
  labs(title = "BMI distribution for patients with and without diabetes", 
       x = "Diabetes", 
       y = "BMI")
```



# Modeling

Converting some of the variables to factors.

```{r}
names = c('HighBP' ,'HighChol', 
          'CholCheck', 'Smoker', 
          'Diabetes_binary', 'Stroke',
          'HeartDiseaseorAttack', 'PhysActivity',
          'Fruits', 'Veggies', 
          'HvyAlcoholConsump', 'Sex',
          'Age','Income', 'GenHlth', 
          'MentHlth', 'PhysHlth', 'DiffWalk',
          'AnyHealthcare', 'NoDocbcCost')
subset[,names] = lapply(subset[,names] , factor)
str(subset)
```

Spiting up data training and validation data sets.

```{r}
set.seed(5)
trainIndex <- createDataPartition(subset$Diabetes_binary, p = .7, 
                                  list = FALSE, 
                                  times = 1)
train_data = subset[trainIndex, ]
val_data = subset[-trainIndex, ]
```


## Log loss

**Log loss**, also known as **logarithmic loss** or **cross-entropy loss**, is a common evaluation metric for binary classification models. It measures the performance of a model by quantifying the difference between predicted probabilities and actual values. Log-loss is indicative of how close the prediction probability is to the corresponding actual/true value, penalizing inaccurate predictions with higher values. Lower log-loss indicates better model performance.


  
Mathematical interpretation: Log Loss is the negative average of the log of corrected predicted probabilities for each instance.

$$log \ loss = -\frac{1}{N} \sum_{i=1}^N y_i log(p(y_i)) + (1-y_i)log(1-p(y_i))$$

$p(y_i)$ is the probability of $1$.

  
$1-p(y_i)$ is the probability of 0.




## Logistic regression

Logistic regression is a statistical and machine learning model used for binary classification tasks. It's a type of regression analysis that's well-suited for predicting the probability of an observation belonging to one of two classes or categories.


  - Logistic regression is used when the response variable is binary, meaning it has two possible outcomes or classes. 
  - Logistic regression uses the `sigmoid` function to model the relationship between the features and the probability of the binary outcome. The logistic function has an S-shaped curve and maps any real-valued number to a value between 0 and 1. $p(x)=\frac{1}{1+e^{-(\beta_0+\beta_1x)}}$. ($p(x)$ is the probability of the dependent variable being 1)
  - The goal of logistic regression is to find the best-fitting model by estimating the coefficients $\beta_0$, $\beta_1$.
  This is typically done using a process called maximum likelihood estimation. The coefficients are adjusted to maximize the likelihood of the observed data given the model.
  
  
Creating lists to store model performance on train and validations data sets.

```{r}
models_performace_train = list()
models_performace_val = list()
```

### Fit Logistic regression model 1

```{r}
train_data$Diabetes_binary_transformed = train_data$Diabetes_binary
val_data$Diabetes_binary_transformed = val_data$Diabetes_binary

levels(train_data$Diabetes_binary_transformed) = make.names(levels(train_data$Diabetes_binary_transformed))
levels(val_data$Diabetes_binary_transformed) = make.names(levels(val_data$Diabetes_binary_transformed))
```

```{r}
str(train_data)
```


```{r}
train.control = trainControl(method = "cv", 
                              number = 5, 
                              summaryFunction=mnLogLoss,
                              classProbs = TRUE)

set.seed(83)
lr_model_1 = train(Diabetes_binary_transformed ~ 
                                   HighChol+
                                   BMI + 
                                   GenHlth, 
                                 data = train_data,
                                 method = "glm", 
                                 family="binomial",
                                 metric="logLoss",
                                 trControl = train.control
                                )
summary(lr_model_1)
```


Create custom function for log loss calculation.

```{r}
calculateLogLoss <- function(predicted_probabilities, true_labels) {
  predicted_probabilities = pmax(pmin(predicted_probabilities, 1 - 1e-15), 
                                 1e-15)

  log_loss <- -mean(true_labels * log(predicted_probabilities) + 
                      (1 - true_labels) * log(1 - predicted_probabilities))
  return(log_loss)
}
```


Calculate log loss for train data set for logistic regression model #1.

```{r}
train_predictions = predict(lr_model_1, 
                             newdata = train_data %>% select(-Diabetes_binary), 
                             type = "prob")

predicted_prob_class1 = train_predictions[, 1]
true_labels = as.integer(as.character(train_data$Diabetes_binary))

log_loss_train_lr_model_1 = calculateLogLoss(predicted_prob_class1, true_labels)
print(paste("Log Loss:", log_loss_train_lr_model_1))

models_performace_train[["logistic_regression_model_1"]] <- log_loss_train_lr_model_1
```



Calculate log loss for validation data set

```{r}
val_predictions = predict(lr_model_1, 
                             newdata = val_data %>% select(-Diabetes_binary), 
                             type = "prob")

predicted_prob_class1 = val_predictions[, 1]
true_labels = as.integer(as.character(val_data$Diabetes_binary))

log_loss_val_lr_model_1 = calculateLogLoss(predicted_prob_class1, true_labels)
print(paste("Log Loss:", log_loss_val_lr_model_1))


models_performace_val[["logistic_regression_model_1"]] = log_loss_val_lr_model_1
```


### Fit Logistic regression model 2


```{r}
train.control = trainControl(method = "cv", 
                              number = 5, 
                              summaryFunction=mnLogLoss,
                              classProbs = TRUE)

set.seed(8)
lr_model_2 = train(Diabetes_binary_transformed ~ 
                                   poly(BMI, 2) + 
                                   HighChol + HeartDiseaseorAttack+
                                   HighChol:HeartDiseaseorAttack,
                                 data = train_data,
                                 method = "glm", 
                                 family="binomial",
                                 metric="logLoss",
                                 trControl = train.control
                                )
summary(lr_model_2)
```


Calculate log loss for train data set

```{r}
train_predictions = predict(lr_model_2, 
                             newdata = train_data %>% select(-Diabetes_binary), 
                             type = "prob")

predicted_prob_class1 = train_predictions[, 1]
true_labels = as.integer(as.character(train_data$Diabetes_binary))

log_loss_train_lr_model_2 = calculateLogLoss(predicted_prob_class1, true_labels)
print(paste("Log Loss:", log_loss_train_lr_model_2))

models_performace_train[["logistic_regression_model_2"]] = log_loss_train_lr_model_2
```

Calculate log loss for validation data set

```{r}
val_predictions = predict(lr_model_2, 
                             newdata = val_data %>% select(-Diabetes_binary), 
                             type = "prob")

predicted_prob_class1 = val_predictions[, 1]
true_labels = as.integer(as.character(val_data$Diabetes_binary))

log_loss_val_lr_model_2 = calculateLogLoss(predicted_prob_class1, true_labels)
print(paste("Log Loss:", log_loss_val_lr_model_2))

models_performace_val[["logistic_regression_model_2"]] = log_loss_val_lr_model_2
```


### Fit Logistic regression model 3

```{r}
train.control = trainControl(method = "cv", 
                              number = 5, 
                              summaryFunction=mnLogLoss,
                              classProbs = TRUE)

set.seed(10)
lr_model_3 = train(Diabetes_binary_transformed ~ Income+
                     Age+GenHlth+
                     HighBP+
                     HeartDiseaseorAttack+
                     poly(BMI, 2),
                   data = train_data,
                   method = "glm", 
                   family="binomial",
                   metric="logLoss",
                   trControl = train.control
                   )
summary(lr_model_3)
```

Calculate log loss for train data set

```{r}
train_predictions = predict(lr_model_3, 
                             newdata = train_data %>% select(-Diabetes_binary), 
                             type = "prob")

predicted_prob_class1 = train_predictions[, 1]
true_labels = as.integer(as.character(train_data$Diabetes_binary))

log_loss_train_lr_model_3 = calculateLogLoss(predicted_prob_class1, true_labels)
print(paste("Log Loss:", log_loss_train_lr_model_3))

models_performace_train[["logistic_regression_model_3"]] = log_loss_train_lr_model_3
```

Calculate log loss for validation data set

```{r}
val_predictions = predict(lr_model_3, 
                             newdata = val_data %>% select(-Diabetes_binary), 
                             type = "prob")

predicted_prob_class1 = val_predictions[, 1]
true_labels = as.integer(as.character(val_data$Diabetes_binary))

log_loss_val_lr_model_3 = calculateLogLoss(predicted_prob_class1, true_labels)
print(paste("Log Loss:", log_loss_val_lr_model_3))

models_performace_val[["logistic_regression_model_3"]] = log_loss_val_lr_model_3
```



## LASSO logistic regression

`LASSO (Least Absolute Shrinkage and Selection Operator) logistic regression` is a statistical method that combines logistic regression with LASSO regularization. It is used for binary classification problems where you want to predict the probability of an event occurring, such as whether a customer will buy a product (yes/no) based on various predictor variables.

How it works:

  -  `LASSO logistic regression` models the probability of an event using the logistic function. It models the log-odds of the event as a linear combination of predictor variables. The logistic function is used to transform the linear combination into probabilities.
  - `LASSO` adds a regularization term to the logistic regression model. The regularization term is a penalty based on the absolute values of the model coefficients (L1 regularization). This penalty encourages some of the coefficient values to become exactly zero, effectively performing feature selection.
  - `LASSO` regularization promotes sparsity in the model. It can automatically select a subset of the most relevant predictor variables by setting the coefficients of irrelevant variables to zero. This helps to reduce overfitting and build more interpretable models.
  - The degree of regularization is controlled by a hyper parameter denoted as $\lambda$.

### Fit and validate LASSO logistic regression


```{r}
train.control <- trainControl(method = "cv",
                              number = 5, 
                              summaryFunction=mnLogLoss,
                              classProbs = TRUE)

set.seed(2)
lasso_log_reg<-train(Diabetes_binary ~., 
                   data = select(train_data, -Diabetes_binary_transformed),
                   method = 'glmnet',
                   #metric="logLoss",
                   tuneGrid = expand.grid(alpha = 1, 
                                          lambda=seq(0, 1, by = 0.1))
)
lasso_log_reg$results
```

Obtained the best tuning parameter $\lambda$ value is

```{r}
lasso_log_reg$bestTune$lambda
```

Plot obtained accuracy for different $\lambda$ values.

```{r}
plot(lasso_log_reg)
```

Calculate log loss for train data set


```{r}
train_predictions = predict(lasso_log_reg, 
                             newdata = train_data %>% select(-Diabetes_binary), 
                             type = "prob")

predicted_prob_class1 = train_predictions[, 1]
true_labels = as.integer(as.character(train_data$Diabetes_binary))

log_loss_train_lasso = calculateLogLoss(predicted_prob_class1, true_labels)
print(paste("Log Loss:", log_loss_train_lasso))

models_performace_train[["lasso"]] = log_loss_train_lasso
```

Calculate log loss for validation data set

```{r}
val_predictions = predict(lasso_log_reg, 
                             newdata = val_data %>% select(-Diabetes_binary), 
                             type = "prob")

predicted_prob_class1 = val_predictions[, 1]
true_labels = as.integer(as.character(val_data$Diabetes_binary))

log_loss_val_lasso = calculateLogLoss(predicted_prob_class1, true_labels)
print(paste("Log Loss:", log_loss_val_lasso))

models_performace_val[["lasso"]] = log_loss_val_lasso
```


## Classification tree model

A Classification tree model is a supervised machine learning model used to predict group membership.

## Random forest model

A Random Forest classification model is a supervised machine learning model used for classification tasks. It is an ensemble of multiple decision trees, where each tree predicts the class label of an input based on a set of features. The final prediction in a Random Forest is determined through a combination of predictions from individual decision trees, often using majority voting for classification tasks.

Random Forest might be chosen over a basic Classification Tree for several reasons:

  - **Generalization** - Random Forest typically offers better generalization to new, unseen data. It reduces the risk of overfitting, which is a common issue with basic Classification Trees.
  - **Higher Accuracy** - Random Forest often provides higher accuracy because it combines multiple decision trees. The majority voting from these trees leads to a more reliable and accurate classification.
  - **Robustness to Noise** - Basic Classification Trees are sensitive to noise in the data, which can lead to overfitting. Random Forest, through ensemble learning, is more robust to noise and outliers.
  - **Reduced Variance** - A basic Classification Tree can vary significantly with small changes in the training data. Random Forest reduces this variance because the ensemble of trees accounts for different sources of variance.
  - **Feature Selection** - Random Forest provides a measure of feature importance. It can help identify which features are most relevant for making predictions. This feature selection is especially valuable when dealing with high-dimensional data.
  
  
```{r}
train_control <- trainControl(
  method = "cv",   
  number = 5,
)

set.seed(11)
rf_model = train(
  Diabetes_binary ~ ., 
  data = select(train_data, -Diabetes_binary_transformed),
  method = "rf",
  tuneGrid = data.frame(mtry = 1:10),
  trControl = train_control
)

rf_model$results
```

```{r}
plot(rf_model)
```



Calculate log loss for train data set


```{r}
train_predictions = predict(rf_model, 
                             newdata = train_data %>% select(-Diabetes_binary), 
                             type = "prob")

predicted_prob_class1 = train_predictions[, 1]
true_labels = as.integer(as.character(train_data$Diabetes_binary))

log_loss_train_rf = calculateLogLoss(predicted_prob_class1, true_labels)
print(paste("Log Loss:", log_loss_train_rf))

models_performace_train[["random_forest"]] = log_loss_train_rf
```

Calculate log loss for validation data set

```{r}
val_predictions = predict(rf_model, 
                             newdata = val_data %>% select(-Diabetes_binary), 
                             type = "prob")

predicted_prob_class1 = val_predictions[, 1]
true_labels = as.integer(as.character(val_data$Diabetes_binary))

log_loss_val_rf = calculateLogLoss(predicted_prob_class1, true_labels)
print(paste("Log Loss:", log_loss_val_rf))

models_performace_val[["random_forest"]] = log_loss_val_rf
```


## New model - Support Vector Machine

Support Vector Machine(SVM) is a supervised machine learning algorithm that is used for both classification and regression tasks. It is a powerful and versatile algorithm known for its ability to handle complex decision boundaries and high-dimensional data. SVM works by finding the *optimal hyperplane* that best separates data points into different classes or predicts a continuous target variable.

Main components of SVM:

  - **Hyperplane** - SVM's core concept is to find the optimal hyperplane that maximizes the margin between two classes in a data set. The hyperplane is the decision boundary that separates data points into different classes. In two dimensions, it's a line; in higher dimensions, it's a hyperplane.
  - **Support Vectors** - Support Vectors are the data points that are closest to the decision boundary, or hyperplane. These support vectors play a crucial role in determining the position and orientation of the hyperplane.
  - **Margin** - The margin is the distance between the decision boundary (hyperplane) and the closest support vectors. SVM aims to maximize this margin, as it represents the separation between classes. The larger the margin, the better the model's generalization.
  - **Kernel Trick** - SVM can handle both linearly separable and non-linearly separable data. The kernel trick allows SVM to transform data into higher-dimensional space, making it possible to find linear separation in this transformed space. Common kernel functions include linear, polynomial, radial basis function (RBF), and sigmoid.
  - **C Parameter** - SVM has a hyper parameter called C, which controls the trade-off between maximizing the margin and minimizing the classification error. Smaller C values lead to a larger margin but may allow some mis-classification, while larger C values lead to a smaller margin with fewer mis-classifications.
  
  
```{r, warning=FALSE}
train_control = trainControl(
  method = "cv",
  number = 5,
  classProbs =  TRUE
)

svm_grid = expand.grid(
  sigma = c(0.01, 0.1, 1),   # Range of sigma values for the RBF kernel
  C = c(0.1, 1, 10)          # Range of C values for regularization
)

svm_model = train(
  Diabetes_binary_transformed ~ ., 
  data = select(train_data, -Diabetes_binary),
  method = "svmRadial",
  trControl = train_control,
  tuneGrid = svm_grid
)
svm_model
```


```{r}
plot(svm_model)

svm_model$bestTune
```

Calculate log loss for train data set


```{r}
train_predictions = predict(svm_model, 
                             newdata = train_data %>% select(-Diabetes_binary_transformed), 
                             type = "prob")

predicted_prob_class1 = train_predictions[, 1]
true_labels = as.integer(as.character(train_data$Diabetes_binary))

log_loss_train_svm = calculateLogLoss(predicted_prob_class1, true_labels)
print(paste("Log Loss:", log_loss_train_svm))

models_performace_train[["svm"]] = log_loss_train_svm
```


Calculate log loss for validation data set

```{r}
val_predictions = predict(svm_model, 
                             newdata = val_data %>% select(-Diabetes_binary_transformed), 
                             type = "prob")

predicted_prob_class1 = val_predictions[, 1]
true_labels = as.integer(as.character(val_data$Diabetes_binary))

log_loss_val_svm = calculateLogLoss(predicted_prob_class1, true_labels)
print(paste("Log Loss:", log_loss_val_svm))

models_performace_val[["svm"]] = log_loss_val_svm
```




```{r}
models_performace_train
models_performace_val
```

The best performed model based on train data set is 
```{r}
print (names(models_performace_train)[which.min(unlist(models_performace_train))])
```

The best performed model based on validation data set is
```{r}
print (names(models_performace_val)[which.min(unlist(models_performace_val))])
```
